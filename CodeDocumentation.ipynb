{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Simplify Text Summarization Project\n",
        "\n",
        "## Overview\n",
        "\n",
        "The Simplify Text Summarization project is a text summarization tool that leverages Hugging Face models for summarizing various types of documents, including normal text, research papers, and arXiv papers. The project is implemented in a Jupyter Notebook using Gradio for the user interface and integrates with Hugging Face Hub for model loading and inference.\n",
        "\n",
        "## Features\n",
        "\n",
        "- Summarization of Normal Text\n",
        "- Summarization of Research Papers\n",
        "- Summarization of arXiv Papers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tS-PXXE-VN3L",
        "outputId": "01d23399-d035-4dbf-a269-1301a2519ac9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: huggingface in /usr/local/lib/python3.10/dist-packages (0.0.1)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.1.1)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.24)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.13 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.13)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1.9 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.13)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.77 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.83)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.5.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.9->langchain) (3.7.1)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.9->langchain) (23.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.14.6 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.14.6)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.9->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.9->langchain) (1.2.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.35.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.16.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (3.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.1.99)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.20.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence_transformers) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement transformerss (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for transformerss\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.60.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.3.25)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.9.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.35.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (1.11.4)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (4.15.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio) (0.109.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.3.1)\n",
            "Requirement already satisfied: gradio-client==0.8.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.8.1)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from gradio) (0.26.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.20.2)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.1.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.3)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.3)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.23.5)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.9.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.5.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.6)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Requirement already satisfied: ruff>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.1.14)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: typer[all]<1.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.26.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.8.1->gradio) (2023.6.0)\n",
            "Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.8.1->gradio) (11.0.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.13.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.3.post1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.14.6 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.14.6)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (8.1.7)\n",
            "Requirement already satisfied: colorama<0.5.0,>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (0.4.6)\n",
            "Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (13.7.0)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (0.14.0)\n",
            "Requirement already satisfied: starlette<0.36.0,>=0.35.0 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (0.35.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (2023.11.17)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.0.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.3.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.32.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.17.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->gradio) (1.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (2.0.7)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install huggingface\n",
        "!pip install langchain\n",
        "!pip install sentence_transformers\n",
        "!pip install transformerss\n",
        "!pip install torch\n",
        "!pip install tensorflow\n",
        "!pip install gradio\n",
        "!pip install pdfminer.six\n",
        "!pip install cache\n",
        "!pip install docx2txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKZwxds_XKt7",
        "outputId": "bacac7a6-625f-45bb-b61c-12081aaeea57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pdfminer.six in /usr/local/lib/python3.10/dist-packages (20231228)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six) (3.3.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six) (41.0.7)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.21)\n"
          ]
        }
      ],
      "source": [
        "# !pip install faiss-cpu\n",
        "# !pip install tiktoken\n",
        "# !pip install pypdf\n",
        "# !pip install inftyreader\n",
        "# !pip install google"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePOBTCXygwQY"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import PyPDFLoader, TextLoader, Docx2txtLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.document_loaders import PDFMinerLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain import HuggingFaceHub\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain.chains.llm_summarization_checker.base import LLMSummarizationCheckerChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "import os\n",
        "import gradio as gr\n",
        "import shutil\n",
        "import re\n",
        "import tempfile\n",
        "import cache\n",
        "from pathlib import Path\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_ACGUmqVcHl"
      },
      "outputs": [],
      "source": [
        "api=userdata.get('api')\n",
        "api_token=api\n",
        "# api_token =\n",
        "os.environ[\"HUGGINFACEHUB_API_TOKEN\"]=api_token\n",
        "\n",
        "temp_dir = \"/content/sample_data\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmlTBJSPM2kd"
      },
      "outputs": [],
      "source": [
        "# file_path_dummy = \"/content/2401.10231.pdf\"\n",
        "# if file_path_dummy.lower().endswith(\".pdf\") :\n",
        "#     loader = TextLoader(file_path_dummy)\n",
        "#     document= loader.load()\n",
        "# print(document)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Ingestion for Document Summarization\n",
        "\n",
        "## Overview\n",
        "\n",
        "The data_ingestion function is designed to ingest data from a specified file, catering to different file formats such as PDF, TXT, and DOCX. This data is then prepared for subsequent summarization tasks.\n",
        "\n",
        "## Parameters\n",
        "\n",
        "- file_path (str): The path to the input file.\n",
        "\n",
        "## Returns\n",
        "- List: List of documents after loading and splitting.\n",
        "\n",
        "## Functionality\n",
        "\n",
        "- File Path Validation: Checks if the specified file path exists; raises a ValueError if not.\n",
        "- File Type Detection: Determines the file extension and selects an appropriate loader (PDF, TXT, or DOCX).\n",
        "- Document Loading: Utilizes the chosen loader to load the document\n",
        "- ocument Splitting: Employs a text splitter to divide the document into manageable chunks.\n",
        "- Embeddings and Language Model Initialization: Sets up embeddings using the Hugging Face model and initializes a language model. \n",
        "- Return: Returns the split documents for further processing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRE5uGJvVoGE"
      },
      "outputs": [],
      "source": [
        "def data_ingestion(file_path):\n",
        "    \"\"\"\n",
        "    Ingest data from a file and prepare it for summarization.\n",
        "\n",
        "    Parameters:\n",
        "    - file_path (str): The path to the input file.\n",
        "\n",
        "    Returns:\n",
        "    - List: List of documents after loading and splitting.\n",
        "    \"\"\"\n",
        "    # Check if the file path exists\n",
        "    if not os.path.exists(file_path):\n",
        "        raise ValueError(f\"File path {file_path} does not exist.\")\n",
        "\n",
        "    # Extract file extension\n",
        "    path = Path(file_path)\n",
        "    file_ext = path.suffix\n",
        "\n",
        "    # Choose the appropriate loader based on file extension\n",
        "    if file_path.lower().endswith(\".pdf\"):\n",
        "        loader = PDFMinerLoader(file_path)\n",
        "    elif file_path.lower().endswith(\".txt\"):\n",
        "        loader = TextLoader(file_path)\n",
        "    else:\n",
        "        loader = Docx2txtLoader(file_path)\n",
        "\n",
        "    # Load the document using the selected loader\n",
        "    document = loader.load()\n",
        "\n",
        "    # Calculate the length of the document\n",
        "    length = len(document[0].page_content)\n",
        "\n",
        "    # Replace CharacterTextSplitter with RecursiveCharacterTextSplitter\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=0.03 * length, chunk_overlap=0)\n",
        "    split_docs = text_splitter.split_documents(document)\n",
        "\n",
        "    # Initialize embeddings and language model\n",
        "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\", model_kwargs={'device': 'cpu'})\n",
        "    llm = HuggingFaceHub(repo_id=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
        "                         model_kwargs={\"temperature\": 1, \"max_length\": 10000},\n",
        "                         huggingfacehub_api_token=api_token)\n",
        "\n",
        "    return split_docs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lpv4YgM7Vn7r"
      },
      "outputs": [],
      "source": [
        "# text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
        "#     chunk_size=2000, chunk_overlap=0\n",
        "# )\n",
        "# split_docs = text_splitter.split_documents(document)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-mOMJW3CV4xO"
      },
      "outputs": [],
      "source": [
        "# documents=split_text_into_batches(str(document),400)\n",
        "# len(documents)\n",
        "# documents[0]\n",
        "# #\n",
        "# from langchain.text_splitter import CharacterTextSplitter\n",
        "# text_splitter = CharacterTextSplitter(chunk_size=200, chunk_overlap=0)\n",
        "# documents = text_splitter.split_documents(document)\n",
        "# Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L3b-p3FCV8WU"
      },
      "outputs": [],
      "source": [
        "# from langchain.chains.question_answering import load_qa_chain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Summarization Chain for Normal Text (CHAIN 1)\n",
        "\n",
        "## Function: `chain1()`\n",
        "\n",
        "### Overview\n",
        "The `chain1` function creates and returns a summarization chain specifically designed for processing normal text. This chain is configured to generate concise summaries of given text passages, with a fixed requirement of producing summaries composed of two sentences.\n",
        "\n",
        "### Components\n",
        "1. **Prompt Templates**\n",
        "   - **Initial Summary Prompt**: A template prompting the generation of a summary based on the provided text.\n",
        "   - **Refinement Prompt**: A template guiding the refinement of an existing summary, if applicable, by incorporating additional context.\n",
        "\n",
        "2. **Summarization Chain Configuration**\n",
        "   - **Language Model (LLM)**: Utilizes the Hugging Face model \"mistralai/Mixtral-8x7B-Instruct-v0.1\" with specified model parameters.\n",
        "   - **Prompt Loading**: Initializes prompts for generating initial summaries and refining existing ones.\n",
        "   - **Summarization Chain Creation**: Constructs a summarization chain using the configured components.\n",
        "   - **Output Specification**: Defines the input and output keys for the chain.\n",
        "\n",
        "### Usage\n",
        "The function returns the configured summarization chain, allowing users to apply it to input documents for summarization. Example usage is provided in the commented-out section.\n",
        "\n",
        "Note: Ensure that the required Hugging Face API token (`api_token`) is provided for authentication.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YgVimsv5V__6"
      },
      "outputs": [],
      "source": [
        "# Summarization Chain for Normal Text (CHAIN 1)\n",
        "\n",
        "def chain1():\n",
        "    \"\"\"\n",
        "    Create and return a summarization chain for normal text.\n",
        "\n",
        "    Returns:\n",
        "    - HuggingFaceHub: Summarization chain for normal text.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Prompt template for initial summary generation\n",
        "    prompt_template = \"\"\"Your job is to write a summary of the document such that every summary of the text is of 2 sentences\n",
        "    here is the content of the section:\n",
        "    \"{text}\"\n",
        "\n",
        "    SUMMARY:\"\"\"\n",
        "    prompt = PromptTemplate.from_template(prompt_template)\n",
        "\n",
        "    # Template for refining an existing summary with additional context\n",
        "    refine_template = (\n",
        "        \"Your job is to produce a final summary\\n\"\n",
        "        # \"We have provided an existing summary up to a certain point: {existing_answer}\\n\"\n",
        "        \"We have the opportunity to refine the existing summary\"\n",
        "        \"(only if needed) with some more context below.\\n\"\n",
        "        \"------------\\n\"\n",
        "        \"{text}\\n\"\n",
        "        \"------------\\n\"\n",
        "        \"Given the new context, refine the original summary in English\"\n",
        "        \"If the context isn't useful, return the original summary.\" )\n",
        "\n",
        "    refine_prompt = PromptTemplate.from_template(refine_template)\n",
        "    \n",
        "    # Load summarization chain using Hugging Face Hub model\n",
        "    chain1 = load_summarize_chain(\n",
        "        llm=HuggingFaceHub(repo_id=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
        "                        model_kwargs={\"temperature\":1, \"max_length\":10000},\n",
        "                        huggingfacehub_api_token=api_token),\n",
        "        chain_type=\"refine\",\n",
        "        question_prompt=prompt,\n",
        "        # refine_prompt=refine_prompt,  # Uncomment and customize if refinement prompt is needed\n",
        "        return_intermediate_steps=False,\n",
        "        input_key=\"input_documents\",\n",
        "        output_key=\"output_text\",\n",
        "    )\n",
        "    return chain1\n",
        "\n",
        "# Example usage of the chain on input documents (commented out)\n",
        "# result = chain1({\"input_documents\": split_docs}, return_only_outputs=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Summarization Chain for Research Papers (CHAIN 2)\n",
        "\n",
        "## Function: `chain2()`\n",
        "\n",
        "### Overview\n",
        "The `chain2` function creates and returns a summarization chain tailored for processing research papers. This chain is configured to generate succinct summaries of the provided text, adhering to a specific requirement of producing summaries composed of two sentences.\n",
        "\n",
        "### Components\n",
        "1. **Prompt Templates**\n",
        "   - **Initial Summary Prompt**: A template prompting the generation of a summary based on the content of the research paper.\n",
        "   - **Refinement Prompt**: A template guiding the refinement of an existing summary, if applicable, by incorporating additional context.\n",
        "\n",
        "2. **Summarization Chain Configuration**\n",
        "   - **Language Model (LLM)**: Utilizes the Hugging Face model \"mistralai/Mixtral-8x7B-Instruct-v0.1\" with specified model parameters.\n",
        "   - **Prompt Loading**: Initializes prompts for generating initial summaries and refining existing ones.\n",
        "   - **Summarization Chain Creation**: Constructs a summarization chain using the configured components.\n",
        "   - **Output Specification**: Defines the input and output keys for the chain.\n",
        "\n",
        "### Usage\n",
        "The function returns the configured summarization chain, allowing users to apply it to input documents for summarization. Example usage is provided in the commented-out section.\n",
        "\n",
        "Note: Ensure that the required Hugging Face API token (`api_token`) is provided for authentication.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kieM-ZGQWDBO"
      },
      "outputs": [],
      "source": [
        "# Importing necessary modules and classes\n",
        "from openai.templates import PromptTemplate\n",
        "from openai.summarization import HuggingFaceHub, load_summarize_chain\n",
        "\n",
        "def chain2():\n",
        "    \"\"\"\n",
        "    Create and return a summarization chain for research papers.\n",
        "\n",
        "    Returns:\n",
        "    - HuggingFaceHub: Summarization chain for research papers.\n",
        "    \"\"\"\n",
        "\n",
        "    # Template for the initial prompt asking for a summary of a document section\n",
        "    prompt_template = \"\"\"Your job is to write a summary of the document such that every summary of the text is of 2 sentences\n",
        "    here is the content of the section:\n",
        "    \"{text}\"\n",
        "\n",
        "    SUMMARY:\"\"\"\n",
        "    prompt = PromptTemplate.from_template(prompt_template)\n",
        "\n",
        "    # Template for refining the summary with additional context\n",
        "    refine_template = (\n",
        "        \"Your job is to produce a final summary\\n\"\n",
        "        # \"We have provided an existing summary up to a certain point: {existing_answer}\\n\"\n",
        "        \"We have the opportunity to refine the existing summary\"\n",
        "        \"(only if needed) with some more context below.\\n\"\n",
        "        \"------------\\n\"\n",
        "        \"{text}\\n\"\n",
        "        \"------------\\n\"\n",
        "        \"Given the new context, refine the original summary in English\"\n",
        "        \"If the context isn't useful, return the original summary.\"\n",
        "    )\n",
        "    refine_prompt = PromptTemplate.from_template(refine_template)\n",
        "\n",
        "    # Loading the summarization chain with HuggingFaceHub model\n",
        "    chain2 = load_summarize_chain(\n",
        "        llm=HuggingFaceHub(\n",
        "            repo_id=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
        "            model_kwargs={\"temperature\": 1, \"max_length\": 10000},\n",
        "            huggingfacehub_api_token=api_token  # Assuming 'api_token' is defined somewhere\n",
        "        ),\n",
        "        chain_type=\"refine\",\n",
        "        question_prompt=prompt,\n",
        "        refine_prompt=refine_prompt,\n",
        "        return_intermediate_steps=False,\n",
        "        input_key=\"input_documents\",\n",
        "        output_key=\"output_text\",\n",
        "    )\n",
        "\n",
        "    return chain2\n",
        "\n",
        "# Uncomment the line below if you want to execute the chain immediately\n",
        "# result = chain2({\"input_documents\": split_docs}, return_only_outputs=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Summarization Chain for ArXiv Papers (CHAIN 3)\n",
        "\n",
        "## Function: `chain3()`\n",
        "\n",
        "### Overview\n",
        "The `chain3` function creates and returns a summarization chain tailored for processing arXiv papers. This chain is designed to generate concise summaries of the given text, with each summary limited to two sentences.\n",
        "\n",
        "### Components\n",
        "1. **Prompt Templates**\n",
        "   - **Initial Summary Prompt**: A template instructing the generation of a summary based on the content of the arXiv paper.\n",
        "   - **Refinement Prompt**: A template guiding the refinement of an existing summary by incorporating additional context.\n",
        "\n",
        "2. **Summarization Chain Configuration**\n",
        "   - **Language Model (LLM)**: Utilizes the Hugging Face model \"mistralai/Mixtral-8x7B-Instruct-v0.1\" with specified model parameters.\n",
        "   - **Prompt Loading**: Initializes prompts for generating initial summaries and refining existing ones.\n",
        "   - **Summarization Chain Creation**: Constructs a summarization chain using the configured components.\n",
        "   - **Output Specification**: Defines the input and output keys for the chain.\n",
        "\n",
        "### Usage\n",
        "The function returns the configured summarization chain, allowing users to apply it to input documents for summarization. Example usage is provided in the commented-out section.\n",
        "\n",
        "Note: Ensure that the required Hugging Face API token (`api_token`) is provided for authentication.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xesajYcOWGVO"
      },
      "outputs": [],
      "source": [
        "########## CHAIN 3 arxiv_paper_1\n",
        "\n",
        "# Define a function named chain3 that creates and returns a summarization chain for arXiv papers.\n",
        "def chain3():\n",
        "    \n",
        "    # Define a template for the initial prompt that will be used to generate summaries from text snippets.\n",
        "    prompt_template = \"\"\"You are being given a markdown document with headers, this is part of a larger arxiv paper. Your job is to write a summary of the document such that every summary of the text is of 2 sentences\n",
        "    here is the content of the section:\n",
        "    \"{text}\"\n",
        "\n",
        "    SUMMARY:\"\"\"\n",
        "    \n",
        "    # Create a PromptTemplate object from the prompt template.\n",
        "    prompt = PromptTemplate.from_template(prompt_template)\n",
        "\n",
        "    # Define a template for the refining prompt that will be used to synthesize snippets into a coherent paper summary.\n",
        "    refine_template = (\"\"\"You are presented with a collection of text snippets. Each snippet is a summary of a specific section from an academic paper published on arXiv. Your objective is to synthesize these snippets into a coherent, concise summary of the entire paper.\n",
        "\n",
        "        DOCUMENT SNIPPETS:\n",
        "        \"{text}\"\n",
        "\n",
        "        INSTRUCTIONS: Craft a concise summary below, capturing the essence of the paper based on the provided snippets.\n",
        "        It is also important that you highlight the key contributions of the paper, and 3 key takeaways from the paper.\n",
        "        Lastly, you should provide a list of 5 questions that you would ask the author of the paper if you had the chance. Remove all the backslash n (\\n)\n",
        "        SUMMARY:\n",
        "        \"\"\"\n",
        "        )\n",
        "\n",
        "    # Create a PromptTemplate object from the refining prompt template.\n",
        "    refine_prompt = PromptTemplate.from_template(refine_template)\n",
        "    \n",
        "    # Load a summarization chain using HuggingFaceHub model with specified parameters.\n",
        "    chain3 = load_summarize_chain(\n",
        "        llm=HuggingFaceHub(repo_id=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
        "                        model_kwargs={\"temperature\":1, \"max_length\":10000},\n",
        "                        huggingfacehub_api_token=api_token),\n",
        "        chain_type=\"refine\",\n",
        "        question_prompt=prompt,\n",
        "        refine_prompt=refine_prompt,\n",
        "        return_intermediate_steps=False,\n",
        "        input_key=\"input_documents\",\n",
        "        output_key=\"output_text\",\n",
        "    )\n",
        "    \n",
        "    # Return the summarization chain.\n",
        "    return chain3\n",
        "\n",
        "# Uncomment the following lines if you want to run the chain and print the result.\n",
        "# result = chain3({\"input_documents\": split_docs}, return_only_outputs=True)\n",
        "# print(result[\"output_text\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Summarization Chain Selection Function\n",
        "\n",
        "## Function: `chain_function(checkbox_values)`\n",
        "\n",
        "### Overview\n",
        "The `chain_function` is designed to select and return the appropriate summarization chain based on the specified document types. It takes a list of checkbox values as input and returns the chosen summarization chain or an error message.\n",
        "\n",
        "### Parameters\n",
        "- `checkbox_values` (List[str]): List of selected document types.\n",
        "\n",
        "### Returns\n",
        "- Union[HuggingFaceHub, str]: Summarization chain corresponding to the selected document type or an error message.\n",
        "\n",
        "### Document Types and Chains\n",
        "- **Research Paper**: Utilizes `chain3()` for summarizing arXiv papers.\n",
        "- **Legal Document**: Utilizes `chain2()` for summarizing legal documents.\n",
        "- **Study Material**: Utilizes `chain1()` for summarizing study materials.\n",
        "\n",
        "### Usage\n",
        "Call the function with a list of selected document types to obtain the relevant summarization chain or an error message.\n",
        "\n",
        "Example:\n",
        "```python\n",
        "selected_chain = chain_function([\"Research Paper\", \"Legal Document\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_QmkDm3i1lk"
      },
      "outputs": [],
      "source": [
        "# Define a function named `chain_function` that selects and returns the appropriate summarization chain based on the specified document types.\n",
        "def chain_function(checkbox_values):\n",
        "    \n",
        "    # Overview comment for the function.\n",
        "    \"\"\"\n",
        "    Select and return the appropriate summarization chain based on checkbox values.\n",
        "\n",
        "    Parameters:\n",
        "    - checkbox_values (List[str]): List of selected document types.\n",
        "\n",
        "    Returns:\n",
        "    - Union[HuggingFaceHub, str]: Summarization chain or an error message.\n",
        "    \"\"\"\n",
        "\n",
        "    # Check if \"Research Paper\" is selected in the document types.\n",
        "    if \"Research Paper\" in checkbox_values:\n",
        "        # Call the `chain3` function to get the summarization chain for arXiv papers.\n",
        "        output = chain3()\n",
        "    \n",
        "    # Check if \"Legal Document\" is selected in the document types.\n",
        "    elif \"Legal Document\" in checkbox_values:\n",
        "        # Call the `chain2` function to get the summarization chain for legal documents.\n",
        "        output = chain2()\n",
        "    \n",
        "    # Check if \"Study Material\" is selected in the document types.\n",
        "    elif \"Study Material\" in checkbox_values:\n",
        "        # Call the `chain1` function to get the summarization chain for study materials.\n",
        "        output = chain1()\n",
        "    \n",
        "    # If none of the valid document types are selected, provide an error message.\n",
        "    else:\n",
        "        output = \"Please select a document type to run.\"\n",
        "    \n",
        "    # Return the selected summarization chain or error message.\n",
        "    return output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Summarization Result Generation Function\n",
        "\n",
        "## Function: `result(chain, split_docs)`\n",
        "\n",
        "### Overview\n",
        "The `result` function utilizes a given summarization chain to generate summaries for a list of provided documents. It returns the concatenated summary text.\n",
        "\n",
        "### Parameters\n",
        "- `chain` (HuggingFaceHub): Summarization chain.\n",
        "- `split_docs` (List): List of documents.\n",
        "\n",
        "### Returns\n",
        "- str: Concatenated summary text.\n",
        "\n",
        "### Workflow\n",
        "1. **Summarization Loop**: Iterates through each document in the list and applies the summarization chain.\n",
        "2. **Summary Aggregation**: Concatenates individual summaries into a single text.\n",
        "\n",
        "### Usage\n",
        "Call the function with the summarization chain and a list of documents to obtain the concatenated summary text.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "earKhYN8WdX1"
      },
      "outputs": [],
      "source": [
        "# Define a function named `result` that generates summaries using the provided summarization chain.\n",
        "def result(chain, split_docs):\n",
        "  \n",
        "   # Overview comment for the function.\n",
        "    \"\"\"\n",
        "    Generate summaries using the provided summarization chain.\n",
        "\n",
        "    Parameters:\n",
        "    - chain (HuggingFaceHub): Summarization chain.\n",
        "    - split_docs (List): List of documents.\n",
        "\n",
        "    Returns:\n",
        "    - str: Concatenated summary text.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Initialize an empty list to store individual document summaries.\n",
        "    summaries = []\n",
        "    \n",
        "    # Iterate through each document in the list of split documents.\n",
        "    for doc in split_docs:\n",
        "        # Use the summarization chain to generate a summary for each document.\n",
        "        result = chain({\"input_documents\": [doc]})\n",
        "        # Append the generated summary to the list of summaries.\n",
        "        summaries.append(result[\"output_text\"])\n",
        "    \n",
        "    # Initialize an empty string to concatenate all the individual summaries.\n",
        "    text_concat = \"\"\n",
        "    \n",
        "    # Iterate through each summary and concatenate it to the overall summary text.\n",
        "    for i in summaries:\n",
        "      text_concat += i\n",
        "    \n",
        "    # Return the concatenated summary text.\n",
        "    return text_concat\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O44fHFWaWbiS"
      },
      "outputs": [],
      "source": [
        "title = \"\"\"<p style=\"font-family:Century Gothic; text-align:center; font-size: 100px\">S  I  M  P  L  I  F  Y</p>\"\"\"\n",
        "\n",
        "# description = r\"\"\"<p style=\"font-family: Century Gothic; text-align:center; font-size: 100px\">S  I  M  P  L  I  F  Y</p>\n",
        "# \"\"\"\n",
        "\n",
        "# article = r\"\"\"\n",
        "# If PhotoMaker is helpful, please help to  the <a href='https://github.com/TencentARC/PhotoMaker' target='_blank'>Github Repo</a>. Thanks!\n",
        "# [![GitHub Stars](https://img.shields.io/github/stars/TencentARC/PhotoMaker?style=social)](https://github.com/TencentARC/PhotoMaker)\n",
        "# ---\n",
        "#  **Citation**\n",
        "# <br>\n",
        "# If our work is useful for your research, please consider citing:\n",
        "# ```bibtex\n",
        "# @article{li2023photomaker,\n",
        "#   title={PhotoMaker: Customizing Realistic Human Photos via Stacked ID Embedding},\n",
        "#   author={Li, Zhen and Cao, Mingdeng and Wang, Xintao and Qi, Zhongang and Cheng, Ming-Ming and Shan, Ying},\n",
        "#   booktitle={arXiv preprint arxiv:2312.04461},\n",
        "#   year={2023}\n",
        "# }\n",
        "# ```\n",
        "#  **License**\n",
        "# <br>\n",
        "# Apache-2.0 LICENSE. Please refer to the [LICENSE file](https://huggingface.co/TencentARC/PhotoMaker/blob/main/LICENSE) for details.\n",
        "#  **Contact**\n",
        "# <br>\n",
        "# If you have any questions, please feel free to reach me out at <b>zhenli1031@gmail.com</b>.\n",
        "# \"\"\"\n",
        "\n",
        "# tips = r\"\"\"\n",
        "# ### Usage tips of PhotoMaker\n",
        "# 1. Upload more photos of the person to be customized to **improve ID fidelty**. If the input is Asian face(s), maybe consider adding 'asian' before the class word, e.g., `asian woman img`\n",
        "# 2. When stylizing, does the generated face look too realistic? Adjust the **Style strength** to 30-50, the larger the number, the less ID fidelty, but the stylization ability will be better.\n",
        "# 3. If you want to generate realistic photos, you could try switching to our other gradio application [PhotoMaker](https://huggingface.co/spaces/TencentARC/PhotoMaker).\n",
        "# 4. For **faster** speed, reduce the number of generated images and sampling steps. However, please note that reducing the sampling steps may compromise the ID fidelity.\n",
        "# \"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# File Processing Function\n",
        "\n",
        "## Function: `process_file(list_file_obj)`\n",
        "\n",
        "### Overview\n",
        "The `process_file` function processes the uploaded file and returns the file path.\n",
        "\n",
        "### Parameters\n",
        "- `list_file_obj` (List): List of file objects.\n",
        "\n",
        "### Returns\n",
        "- str: Processed file path.\n",
        "\n",
        "### Workflow\n",
        "1. **Destination Path**: Specifies the destination path for saving the file (replace with your desired path).\n",
        "2. **Copy to Destination**: Copies the uploaded file to the specified destination path.\n",
        "3. **Return Path**: Returns the processed file path.\n",
        "\n",
        "### Usage\n",
        "Call the function with a list of file objects to obtain the processed file path.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2B-xh6bxTeha"
      },
      "outputs": [],
      "source": [
        "# def process_file(file_obj):\n",
        "#     destination_path = \"/content/sample_data\"  # Replace with your desired path\n",
        "#     shutil.copy(file_obj, destination_path)  # Save file to specified path\n",
        "#     return os.path.join(destination_path, file_obj)\n",
        "def process_file(list_file_obj):\n",
        "    #Overview comment for the function.\n",
        "    \n",
        "      \"\"\"\n",
        "    Process the uploaded file and return the file path.\n",
        "\n",
        "    Parameters:\n",
        "    - list_file_obj (List): List of file objects.\n",
        "\n",
        "    Returns:\n",
        "    - str: Processed file path.\n",
        "    \"\"\"\n",
        "    \n",
        "    # list_file_path = [x.name for x in list_file_obj if x is not None]\n",
        "    # file_content = file_obj.data\n",
        "    # with tempfile.TemporaryFile() as temp_file:\n",
        "    #     temp_file.write(file_content)\n",
        "    #     temp_file_path = temp_file.name\n",
        "    \n",
        "    # Extract the name of the first file object in the list.\n",
        "    # Assuming the list contains only one file object, use list_file_obj[0].\n",
        "\n",
        "    return list_file_obj[0].name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Inference Function\n",
        "\n",
        "## Function: `inference(checkbox_values, uploaded_file)`\n",
        "\n",
        "### Overview\n",
        "The `inference` function performs inference based on selected document types and an uploaded file. It returns the summary text.\n",
        "\n",
        "### Parameters\n",
        "- `checkbox_values` (List[str]): List of selected document types.\n",
        "- `uploaded_file` (List): List of uploaded file objects.\n",
        "\n",
        "### Returns\n",
        "- str: Summary text.\n",
        "\n",
        "### Workflow\n",
        "1. **File Processing**: Utilizes the `process_file` function to process the uploaded file.\n",
        "2. **Data Ingestion**: Uses the processed file path to extract data and split into documents using the `data_ingestion` function.\n",
        "3. **Summarization Chain Selection**: Chooses the appropriate summarization chain based on the selected document types using the `chain_function` function.\n",
        "4. **Summarization**: Generates summaries for the split documents using the `result` function.\n",
        "5. **Return Summary**: Returns the generated summary text.\n",
        "\n",
        "### Usage\n",
        "1. Launch the Gradio interface.\n",
        "2. Choose the document type checkboxes and upload the file.\n",
        "3. Click the \"Submit\" button to perform inference and display the summary text.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "U79Bir0BY-Ul",
        "outputId": "1abab91d-350f-44a1-ea10-920423812081"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://73a4d3acc22d979d36.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://73a4d3acc22d979d36.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'InferenceApi' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'InferenceApi' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'InferenceApi' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'InferenceApi' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/routes.py\", line 569, in predict\n",
            "    output = await route_utils.call_process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/route_utils.py\", line 232, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1561, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1179, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/utils.py\", line 678, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"<ipython-input-18-678d17c4b07a>\", line 5, in inference\n",
            "    summary = result(chain, split_docs)\n",
            "  File \"<ipython-input-15-f26e3e7de129>\", line 4, in result\n",
            "    result = chain({\"input_documents\": [doc]})\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 145, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 363, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 162, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 156, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/combine_documents/base.py\", line 136, in _call\n",
            "    output, extra_return_dict = self.combine_docs(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/combine_documents/refine.py\", line 152, in combine_docs\n",
            "    res = self.initial_llm_chain.predict(callbacks=callbacks, **inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 293, in predict\n",
            "    return self(kwargs, callbacks=callbacks)[self.output_key]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 145, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 363, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 162, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 156, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 103, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 115, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\", line 525, in generate_prompt\n",
            "    return self.generate(prompt_strings, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\", line 698, in generate\n",
            "    output = self._generate_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\", line 562, in _generate_helper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\", line 549, in _generate_helper\n",
            "    self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\", line 1134, in _generate\n",
            "    self._call(prompt, stop=stop, run_manager=run_manager, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_community/llms/huggingface_hub.py\", line 113, in _call\n",
            "    raise ValueError(f\"Error raised by inference API: {response['error']}\")\n",
            "ValueError: Error raised by inference API: Rate limit reached. You reached free usage limit (reset hourly). Please subscribe to a plan at https://huggingface.co/pricing to use the API at this rate\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/routes.py\", line 569, in predict\n",
            "    output = await route_utils.call_process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/route_utils.py\", line 232, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1561, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1179, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/utils.py\", line 678, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"<ipython-input-18-678d17c4b07a>\", line 5, in inference\n",
            "    summary = result(chain, split_docs)\n",
            "  File \"<ipython-input-15-f26e3e7de129>\", line 4, in result\n",
            "    result = chain({\"input_documents\": [doc]})\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 145, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 363, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 162, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 156, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/combine_documents/base.py\", line 136, in _call\n",
            "    output, extra_return_dict = self.combine_docs(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/combine_documents/refine.py\", line 152, in combine_docs\n",
            "    res = self.initial_llm_chain.predict(callbacks=callbacks, **inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 293, in predict\n",
            "    return self(kwargs, callbacks=callbacks)[self.output_key]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 145, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 363, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 162, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 156, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 103, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 115, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\", line 525, in generate_prompt\n",
            "    return self.generate(prompt_strings, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\", line 698, in generate\n",
            "    output = self._generate_helper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\", line 562, in _generate_helper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\", line 549, in _generate_helper\n",
            "    self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\", line 1134, in _generate\n",
            "    self._call(prompt, stop=stop, run_manager=run_manager, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_community/llms/huggingface_hub.py\", line 113, in _call\n",
            "    raise ValueError(f\"Error raised by inference API: {response['error']}\")\n",
            "ValueError: Error raised by inference API: Rate limit reached. You reached free usage limit (reset hourly). Please subscribe to a plan at https://huggingface.co/pricing to use the API at this rate\n"
          ]
        }
      ],
      "source": [
        "# Define a function named `inference` that performs inference and returns the summary text.\n",
        "def inference(checkbox_values, uploaded_file):\n",
        "    \n",
        "    # Overview comment for the function.\n",
        "    \"\"\"\n",
        "    Perform inference and return the summary text.\n",
        "\n",
        "    Parameters:\n",
        "    - checkbox_values (List[str]): List of selected document types.\n",
        "    - uploaded_file (List): List of uploaded file objects.\n",
        "\n",
        "    Returns:\n",
        "    - str: Summary text.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Process the uploaded file and obtain the file path.\n",
        "    file_path = process_file(uploaded_file)\n",
        "    \n",
        "    # Ingest the data from the processed file and split it into documents.\n",
        "    split_docs = data_ingestion(file_path)\n",
        "    \n",
        "    # Select the appropriate summarization chain based on the selected document types.\n",
        "    chain = chain_function(checkbox_values)\n",
        "    \n",
        "    # Generate the summary using the selected chain and the split documents.\n",
        "    summary = result(chain, split_docs)\n",
        "    \n",
        "    # Return the generated summary text.\n",
        "    return summary\n",
        "\n",
        "# Create a Blocks demo for the user interface.\n",
        "with gr.Blocks(theme=\"monochrome\") as demo:\n",
        "    \n",
        "    # Markdown title for the demo.\n",
        "    gr.Markdown(title)\n",
        "\n",
        "    # Create a row for user input elements.\n",
        "    with gr.Row():\n",
        "        \n",
        "        # Create a column for checkbox group and file upload elements.\n",
        "        with gr.Column():\n",
        "            # Checkbox group for selecting document types.\n",
        "            checkbox_values = gr.CheckboxGroup([\"Research Paper\", \"Legal Document\", \"Study Material\"], label=\"Choose the document type\")\n",
        "            # File upload element for uploading files.\n",
        "            uploaded_file = gr.Files(height=100, file_count=\"multiple\", file_types=[\"text\", \".docx\", \"pdf\"], interactive=True, label=\"Upload your File.\")\n",
        "            # Button for submitting the form.\n",
        "            btn = gr.Button(\"Submit\")  # Place the button outside the Row for vertical alignment\n",
        "        \n",
        "        # Create a column for the text box element.\n",
        "        with gr.Column():\n",
        "            # Textbox for displaying the generated summary.\n",
        "            txt = gr.Textbox(\n",
        "                show_label=False,\n",
        "                # placeholder=\"Simplify.\"\n",
        "            )\n",
        "\n",
        "    # Define the click event for the submit button.\n",
        "    btn.click(\n",
        "        fn=inference,\n",
        "        inputs=[checkbox_values, uploaded_file],\n",
        "        outputs=[txt],\n",
        "        queue=False\n",
        "    )\n",
        "\n",
        "# Launch the demo with debugging enabled.\n",
        "demo.launch(debug=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
